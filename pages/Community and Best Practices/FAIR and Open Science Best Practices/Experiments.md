---
order: 3
---
# For Experiments
# FAIR Experiments Best Practices EarthCODE

In EarthCODE, **Experiments** are defined as a specific execution of a workflow which produced a [Product](./Data.md). An Experiment captures the full context of how a Product was generated, linking together workflows, inputs, and configuration in a way that makes results **reusable and reproducible**.

An Experiment in EarthCODE typically includes:
- A human-readable description of the purpose and context  
- A machine-executable workflow that transforms inputs into outputs  
- A definition of the input data  
- A configuration specifying parameters and settings used at runtime  

Together, these components ensure that scientific results can be re-run, validated, and built upon. Experiments are described using structured **OGC API Records metadata**, which provide both the semantic and technical context for discovery and reuse across the Open Science Catalog.

![Experiments](/img/terms/workflow-components.svg)


:::details Experiment Components
- **Experiment Metadata**: Central description that ties together workflow, inputs, configuration, and outputs.  
- **Purpose & Context**: Concise summary explaining what the experiment achieves.  
- **Workflow**: Link to a [Workflow](./Workflows.md) executable process definition (e.g. openEO graph, CWL workflow, Jupyter Notebook, MLflow model).  
- **Input Data**: Products or datasets used as inputs, linked via unique identifiers.  
- **Configuration**: Parameters, thresholds, or runtime settings applied when executing the workflow.  
- **Output Products**: The resulting datasets, published as EarthCODE Products with references back to the experiment.  
:::

In short, **a workflow defines the process**, but **an experiment defines the full execution**: inputs, configuration, workflow, and outputs. This layered approach ensures that Products published in EarthCODE are not only FAIR but also traceable, reproducible, and citable.


## FAIR Checklist

:::warning
Experiments are typically generated by EarthCODE integrated platforms rather than manually. You can describe the metadata for an experiment by hand, but first make sure to explore using integrated platforms tools! (e.g. [Deep-Code](https://github.com/deepesdl/deep-code/tree/main) for the DeepESDL platform)
:::

Use this checklist to prepare your **Experiment** for publication in EarthCODE.

<ClientOnly>
  <Checklist
    title="FAIR Experiment Preparation"
    :items="[
      'See available [EarthCODE Integrated Platforms](../../../Technical%20Documentation/Platforms/index.md) and their capabilities for publishing experiments',
      'Checkout an example experiment to see what you need to produce, e.g. [ESA CCI permafrost](https://opensciencedata.esa.int/experiments/esa-cci-permafrost/record)',
      'Link the generating workflow via a stable identifier (e.g., `osc:workflow`) and ensure the workflow record/version exists — see [Workflows](./Workflows.md)',
      'Document inputs & configuration: provide an `input.yaml` (or JSON) with dataset identifiers, spatial/temporal filters, parameters',
      'Capture the execution environment: add `environment.yaml` or a container image/tag; include kernel info if using Jupyter',
      'Add project and contacts (ESA project id, consortium, technical officer, PIs, websites, ORCID)',
      'Select relevant OSC [Themes](https://opensciencedata.esa.int/themes/catalog), [Variables](https://opensciencedata.esa.int/variables/catalog), and [Missions](https://opensciencedata.esa.int/eo-missions/catalog)',
      'Test on a small sample and re-run to confirm reproducibility; note runtime and resource requirements',
    ]"
    storage-key="earthcode-experiment"
  />
</ClientOnly>


## FAIR EarthCODE Experiments Standards
EarthCODE's standards for FAIR experiments follow the principles from [Applying the FAIR Principles to computational workflows](https://www.nature.com/articles/s41597-025-04451-9), in combination with [FAIR Workflows](./Workflows.md), where:

<table style="width:100%; table-layout:fixed; border-collapse:collapse;">
  <colgroup>
    <col style="width:50%">
    <col style="width:50%">
  </colgroup>
  <thead>
    <tr>
      <th style="text-align:left; padding:10px; border:1px solid #ddd;">Findable (F)</th>
      <th style="text-align:left; padding:10px; border:1px solid #ddd;">Accessible (A)</th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">
        <p><strong>F1</strong> — Experiments are assigned globally unique, persistent identifiers (e.g., <code>id</code> and stable <code>self</code> link); DOIs may be added via <code>sci:doi</code> when available.</p>
        <p><strong>F1.1</strong> — Components at different granularity have distinct identifiers and links (e.g., <code>links.input</code> → <code>input.yaml</code>, <code>links.environment</code> → <code>environment.yaml</code>, <code>child</code> → Product).</p>
        <p><strong>F1.2</strong> — Versions of experiments are explicitly identified (e.g., a <code>version</code> property or versioned DOI where applicable).</p>
        <p><strong>F2</strong> — Experiments are described with rich OGC API Records metadata (title, description, keywords, themes, contacts, inputs, environment, links).</p>
        <p><strong>F3</strong> — Metadata clearly and explicitly include the experiment identifier (and version when present).</p>
        <p><strong>F4</strong> — Experiments are indexed and searchable in the <a href="https://opensciencedata.esa.int">ESA Open Science Catalog</a> and browseable via the STAC/Records browser.</p>
      </td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">
        <p><strong>A1</strong> — Experiment records and their components are retrievable by identifier over standardized protocols (HTTPS/OGC API Records); linked artifacts (e.g., YAML, notebooks) resolve directly.</p>
        <p><strong>A1.1</strong> — Protocols are open, free, and universally implementable (HTTPS, JSON).</p>
        <p><strong>A1.2</strong> — Where needed, links may employ authentication/authorization (e.g., platform endpoints), while keeping metadata itself open.</p>
        <p><strong>A2</strong> — Metadata remain accessible in the catalog even if some external resources (e.g., a platform or repository) become unavailable.</p>
      </td>
    </tr>
    <tr>
      <th style="text-align:left; padding:10px; border:1px solid #ddd;">Interoperable (I)</th>
      <th style="text-align:left; padding:10px; border:1px solid #ddd;">Reusable (R)</th>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">
        <p><strong>I1</strong> — Experiments and their run context use formal, accessible representations (OGC API Records in JSON); the referenced workflow must follow EarthCODE workflow standards (see <a href="./Workflows.md">Workflows</a>).</p>
        <p><strong>I2</strong> — Metadata use controlled vocabularies (e.g., EarthCODE OSC themes/variables) and standard schemas.</p>
        <p><strong>I3</strong> — Experiments specify inputs/outputs and configuration in community formats (e.g., YAML for params, COG/Zarr/NetCDF for data) to enable exchange; workflow interface details are defined in <a href="./Workflows.md">Workflows</a>.</p>
        <p><strong>I4</strong> — Records include qualified references to related objects: <code>related</code> → Project/Theme, <code>related</code> → Workflow, <code>child</code> → resulting Product, and direct links to <code>input</code>/<code>environment</code>.</p>
      </td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">
        <p><strong>R1</strong> — Experiments are described with accurate, relevant attributes (purpose, inputs, configuration, execution environment such as <code>jupyter_kernel_info</code>).</p>
        <p><strong>R1.1</strong> — A clear, accessible license is stated for the experiment record and any embedded artifacts (e.g., notebooks).</p>
        <p><strong>R1.2</strong> — Components (inputs, notebooks, environment files) carry their own clear licenses when applicable.</p>
        <p><strong>R1.3</strong> — Provenance links connect the experiment to the generating workflow and resulting product(s), enabling validation and re-runs.</p>
        <p><strong>R2</strong> — Experiments may reference other workflows or experiments to indicate alternatives, dependencies, or comparisons.</p>
        <p><strong>R3</strong> — Experiments align with Earth Observation community standards (OGC API Records, STAC/OSC vocabularies; preferred data formats like COG/Zarr/GeoParquet/NetCDF).</p>
      </td>
    </tr>
  </tbody>
</table>


### EarthCODE FAIR Experiment Example

For example the [**ESA CCI Permafrost (Experiment)**](https://opensciencedata.esa.int/experiments/esa-cci-permafrost/record). Published as an OGC API Record with a stable id and self link **(F1, F3)**, it provides rich metadata (title, description, keywords, contacts, theme) in JSON **(F2, I1)** and is indexed in the ESA Open Science Catalog **(F4)**. The record exposes distinct, citable components—input.yaml and environment.yaml—to capture parameters and the execution environment **(F1.1, I4, R1)**. All resources are retrievable over open HTTPS **(A1, A1.1)**, and catalog metadata persists even if external endpoints change **(A2)**. Interoperability is achieved via OSC themes (e.g., cryosphere) and standard representations (JSON/YAML) **(I2, I3)**, while qualified links connect the experiment to its generating [**workflow**](https://opensciencedata.esa.int/stac-browser/#/products/esa-cci-permafrost/collection.json) and resulting [**product**](https://opensciencedata.esa.int/stac-browser/#/workflows/esa-cci-permafrost/record.json) **(I4, R1.3)**. The record declares a license **(R1.1)** and aligns with EO community standards (OGC API Records; notebook environment specified via jupyter_kernel_info) **(R3)**.

:::details
```json
{
  "id": "esa-cci-permafrost",
  "title": "ESA CCI permafrost",
  "type": "Feature",
  "conformsTo": [
    "http://www.opengis.net/spec/ogcapi-records-1/1.0/req/record-core"
  ],
  "geometry": null,
  "properties": {
    "created": "2025-03-17T14:30:23.650003+00:00",
    "updated": "2025-03-17T14:30:23.650003+00:00",
    "type": "experiment",
    "title": "ESA CCI permafrost",
    "description": "cube generation workflow for esa-cci-permafrost",
    "jupyter_kernel_info": {
      "name": "deepesdl-xcube-1.8.3",
      "python_version": 3.11,
      "env_file": "https://github.com/deepesdl/cube-gen/blob/main/Permafrost/environment.yml"
    },
    "keywords": [
      "Earth Science"
    ],
    "contacts": [
      {
        "name": "Tejas Morbagal Harish",
        "organization": "Brockmann Consult GmbH",
        "position": "",
        "links": [
          {
            "rel": "about",
            "type": "text/html",
            "href": "https://www.brockmann-consult.de/"
          }
        ],
        "contactInstructions": "",
        "roles": [
          "principal investigator"
        ]
      }
    ],
    "themes": [
      {
        "concepts": [
          {
            "id": "cryosphere"
          }
        ],
        "scheme": "https://github.com/stac-extensions/osc#theme"
      }
    ],
    "formats": [],
    "license": "proprietary",
    "osc:workflow": "esa-cci-permafrost"
  },
  "linkTemplates": [],
  "links": [
    {
      "rel": "root",
      "href": "../../catalog.json",
      "type": "application/json",
      "title": "Open Science Catalog"
    },
    {
      "rel": "parent",
      "href": "../catalog.json",
      "type": "application/json",
      "title": "Experiments"
    },
    {
      "rel": "related",
      "href": "../../workflows/esa-cci-permafrost/record.json",
      "type": "application/json",
      "title": "Workflow: ESA CCI permafrost"
    },
    {
      "rel": "child",
      "href": "../../products/esa-cci-permafrost/collection.json",
      "type": "application/json",
      "title": "esa-cci-permafrost"
    },
    {
      "rel": "related",
      "href": "../../projects/deep-earth-system-data-lab/collection.json",
      "type": "application/json",
      "title": "Project: DeepESDL"
    },
    {
      "rel": "input",
      "href": "./input.yaml",
      "type": "application/yaml",
      "title": "Input parameters"
    },
    {
      "rel": "environment",
      "href": "./environment.yaml",
      "type": "application/yaml",
      "title": "Execution environment"
    },
    {
      "rel": "self",
      "href": "https://esa-earthcode.github.io/open-science-catalog-metadata/experiments/esa-cci-permafrost/record.json",
      "type": "application/json"
    },
    {
      "rel": "related",
      "href": "../../themes/cryosphere/catalog.json",
      "type": "application/json",
      "title": "Theme: Cryosphere"
    }
  ]
}
```
:::



<!-- 

. This ensures that results are not only discoverable but also repeatable and reusable across different platforms.



WORKFLOWS FOCUS ON RESEARCH SOFTWARE, THIS FOCUSES ON EXPERIMENTS!


 Workflows also automate critical processes that require standardization and increased reproducibility, improving efficiency by removing humans from the analytical process, at times dispensing with the need for manual management of data flow through a set of processing steps, and reducing the need for repeat analyses due to human error and/or bias. Moreover, automation ensures that computational experiments can be replicated. Workflows also provide a documented record of the computational processes, which helps in understanding, reviewing, and auditing those processes. As scientific activity often includes the exploration of analysis variance, modifying workflows to understand effects and changes on data products is simpler when those workflows are clearly described and comparable. Researchers can reuse workflows to re-analyze and adapt to incorporate new methods, tools, or data sources. Sharing and reusing workflows supports team collaboration and standardizes processes and analysis methods


As digital objects to be shared, discovered, and reused, computational workflows benefit from the FAIR principles, which stand for Findable, Accessible, Interoperable, and Reusable.
..


Computational workflows are a special kind of software specifically targeted at handling multi-step, multi-code data pipelines, data analyses, and other data-handling operations


..


explicit abstraction from the run mechanics in some form of high-level workflow language that precisely specifies the flow of data between the components, relying on a dedicated management system concerned with data handling and code execution


At the simplest end of the complexity spectrum, the workflow language might consist of a script (e.g. Bash, Python, R) or enumerated stages in an electronic research notebook (e.g. Jupyter, RStudio, Apache Zeppelin, etc.) with a set of instructions that use inputs and outputs to pipe the results together. 




A workflow is the formal specification of the data flow and execution control between executable components, the expected datasets, and parameter files. Its complexity can be composed, and its overall process can be abstracted away from its execution. A workflow run is the instantiation of the workflow with inputs (parameters files, input datasets) and outputs (output data, the provenance execution log and lineage of data products).

>>>Researchers can reuse workflows to re-analyze and adapt to incorporate new methods, tools, or data sources. Sharing and reusing workflows supports team collaboration and standardizes processes and analysis methods


The Findable, Accessible, Interoperable, and Reusable (FAIR) principles aim to maximize the value and impact of scientific digital objects. Such objects cannot be reused if they cannot be found, accessed, or understood; they cannot be combined if they are not interoperable


Workflows that are chiefly concerned with the processing and creation of data are typically designed to be tightly coupled with their data, including test data and the provenance lineage history of data products. Therefore, workflows have an important role to play in ensuring that the data products they use and produce are FAIR.




>>>>




--------------- A workflow associated with a publication may still be examined as a method, and its provenance may be inspected; the description should be enough to be translated for another workflow system. Apart from manual or AI-assisted porting of code, this can also happen via “Rosetta” workflow languages like CWL and WDL (as e.g. done in MGnify25 and by Snakemake’s CWL export).


-- Papers and handboooks about the method are necessary 



We adapt software principles for I3 and I4 to explicitly refer to the domain standard description of input and outputs of the workflow executable components. As data components of a workflow, the expected input and output datasets, benchmarks and parameters, and the actual datasets and parameter files from a workflow run, should also adhere to community standards (data principle R1.3), as should intermediate data derived during the execution. The principles encourage workflow portability across different types of computational environments (e.g., via containerization or OS-agnostic package management)13 and, ideally, easy translation from one language/management system to another or at least compatibility and seamless integration (in case of sub-workflows).


Reusability of the workflow as an executable method with modifications to its parameters and input files is an expected and anticipated use of the workflow, tied up in the quality of its documentation and the accessibility of computational infrastructure capable of executing it.



---
Here, we demonstrate the application of the FAIR principles to a workflow run. Recall from our previous definitions that a workflow run is the instantiation of a workflow with inputs (parameters files, input datasets) and outputs (output data, the provenance execution log and lineage of data products)

------- ---change experiment for multiple workflow links in order --- implemrbt likje https://www.researchobject.org/workflow-run-crate/profiles/0.1/provenance_run_crate




Computational workflows are key instruments for the advancement in scientific research, potentially revolutionizing how data is managed, analyzed, and shared. Workflows not only serve as software that can be used by experts and non-coders alike; they also serve as documentation of scientific processes, encapsulating not only the data and software used but also the context and conditions under which discoveries were made. It is expected that this comprehensive documentation will not only enhance the credibility of research findings but will also facilitate the replication and validation of scientific results across diverse settings and by different research teams.

FAIR data and FAIR software principles both apply to workflows, combining structured, well-described data with portable, well-documented software creating a powerful framework for advancing scientific knowledge. Moreover, the next generation of workflows – assisted auto-assembly, generative workflows, dynamic reconfiguration, and so on – will require rich, machine-actionable metadata.

  -->


  <!-- Our standards closely follows the [Applying the FAIR Principles to computational workflow](https://www.nature.com/articles/s41597-025-04451-9)


:::details FAIR Workflows Principles

<table style="width:100%; table-layout:fixed; border-collapse:collapse;">
  <colgroup>
    <col style="width:70%">
    <col style="width:30%">
  </colgroup>

  <thead>
    <tr>
      <th style="text-align:left; padding:10px; border:1px solid #ddd;">Guideline</th>
      <th style="text-align:left; padding:10px; border:1px solid #ddd;">Based on</th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">F1. A workflow is assigned a globally unique and persistent identifier.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-F1 and S-F1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">F1.1. Components of the workflow representing levels of granularity are assigned distinct identifiers.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">S-F1.1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">F1.2. Different versions of the workflow are assigned distinct identifiers.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">S-F1.2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">F2. A workflow and its components are described with rich metadata.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-F2 and S-F2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">F3. Metadata clearly and explicitly include the identifier of the workflow, and workflow versions, that they describe.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-F3 and S-F3</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">F4. Metadata and workflow are registered or indexed in a searchable FAIR resource.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-F4 and S-F4</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">A1. Workflow and its components are retrievable by their identifiers using a standardized communications protocol.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-A1 and S-A1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">A1.1. The protocol is open, free, and universally implementable.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-A1.1 and S-A1.1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">A1.2. The protocol allows for an authentication and authorization procedure, when necessary.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-A1.2 and S-A1.2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">A2. Metadata are accessible, even when the workflow is no longer available.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-A2 and S-A2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">I1. Workflow and its metadata (including workflow run provenance) use a formal, accessible, shared, transparent, and broadly applicable language for knowledge representation.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-I1 and S-R1.2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">I2. Metadata and workflow use vocabularies that follow FAIR principles.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-I2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">I3. Workflow is specified in a way that allows its components to read, write, and exchange data (including intermediate data), in a way that meets domain-relevant standards.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-R3 and S-I1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">I4. Workflow and its metadata (including workflow run provenance) include qualified references to other objects and the workflow’s components.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-I3, S-I2, and S-R1.2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">R1. Workflow is described with a plurality of accurate and relevant attributes.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-R1 and S-R1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">R1.1. Workflow is released with a clear and accessible license.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-R1.1 and S-R1.1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">R1.2. Components of the workflow representing levels of granularity are given clear and accessible licenses.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-R1.1 and S-R1.1</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">R1.3. Workflow is associated with detailed provenance of the workflow and of the products of the workflow.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-R1.2 and S-R1.2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">R2. Workflow includes qualified references to other workflows.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-I3 and S-R2</td>
    </tr>
    <tr>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">R3. Workflow meets domain-relevant community standards.</td>
      <td style="vertical-align:top; padding:10px; border:1px solid #eee;">D-R1.3 and S-R3</td>
    </tr>
  </tbody>
</table>

::: -->